{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450efcb2-1015-422b-a7a6-1443a1c4491a",
   "metadata": {},
   "source": [
    "#### Imoprt Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2340b932-3928-4494-abac-f2df1d1f318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from openai.error import RateLimitError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52143ba8-3765-4edf-86f3-86de7c121625",
   "metadata": {},
   "source": [
    "#### Configure Azure OpenAI (adjust these values in your .env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc49a8d6-07f8-4118-b587-324f65b51e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://your-resource-name.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"  \n",
    "openai.api_key = \"your_api_key\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT=\"your_embedding_deployment\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e272fc-5450-4363-a1e7-bb5472a5e63f",
   "metadata": {},
   "source": [
    "#### Create Functions for Embedding Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673c2fe4-ad2a-4f49-8909-45ea9af2ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batch(texts, deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT, max_retries=5):\n",
    "    \"\"\"\n",
    "    Get embeddings for a batch of texts with retry mechanism on rate limit errors.\n",
    "    \"\"\"\n",
    "    retries = 0\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.Embedding.create(\n",
    "                input=texts,\n",
    "                engine=deployment  # Use your Azure embedding deployment name\n",
    "            )\n",
    "            embeddings = [np.array(item['embedding'], dtype=np.float32) for item in response['data']]\n",
    "            return embeddings\n",
    "        except RateLimitError as e:\n",
    "            retries += 1\n",
    "            if retries > max_retries:\n",
    "                raise e\n",
    "            delay = 3 * (2 ** (retries - 1))\n",
    "            print(f\"Rate limit error encountered (batch), retrying in {delay} seconds... (Attempt {retries}/{max_retries})\")\n",
    "            time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8985d9a3-96b3-4216-988f-3ef995f1ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(row, columns):\n",
    "    \"\"\"\n",
    "    Combine specified columns from a row into a single text string.\n",
    "    \"\"\"\n",
    "    return \" | \".join(f\"{col}: {row[col]}\" for col in columns if col in row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56bbb87-488d-4c17-b77a-745ec724abd0",
   "metadata": {},
   "source": [
    "#### Push Webscraped DF CSV to Embedding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53d34b4-42a6-48f7-af48-581cb64bb642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows to process: 210\n",
      "Processing batch 0 to 50 out of 210\n",
      "Processing batch 50 to 100 out of 210\n",
      "Processing batch 100 to 150 out of 210\n",
      "Processing batch 150 to 200 out of 210\n",
      "Processing batch 200 to 210 out of 210\n",
      "Returning vectorized dataset with embeddings.... \n"
     ]
    }
   ],
   "source": [
    "def vectorize_dataset(csv_path='master_agent_data.csv',\n",
    "                      output_parquet='master_agent_data_with_embeddings.parquet',\n",
    "                      batch_size=50):\n",
    "    \"\"\"\n",
    "    Compute embeddings for the dataset and save it as a Parquet file.\n",
    "    \"\"\"\n",
    "    # Load the CSV data\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Define which columns to combine (adjust as needed)\n",
    "    text_columns = [\n",
    "        \"TEAM\", \"CONF\", \"DIVISION\", \"GP\", \"PPG\", \"oPPG\", \"pDIFF\", \"PACE\", \"oEFF\", \"dEFF\", \"W\", \"L\", \"WIN%\", \"SEASON\"\n",
    "    ]\n",
    "    \n",
    "    # Create a list of combined text for each row\n",
    "    texts = []\n",
    "    for _, row in df.iterrows():\n",
    "        text = combine_data(row, text_columns)\n",
    "        texts.append(text)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    total = len(texts)\n",
    "    print(f\"Total rows to process: {total}\")\n",
    "    \n",
    "    # Process texts in batches to avoid rate limits\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch_texts = texts[i: i + batch_size]\n",
    "        print(f\"Processing batch {i} to {i + len(batch_texts)} out of {total}\")\n",
    "        batch_embeddings = get_embeddings_batch(batch_texts)\n",
    "        all_embeddings.extend(batch_embeddings)\n",
    "    \n",
    "    # Save the computed embeddings as a new column in the DataFrame.\n",
    "    # Convert each NumPy array to a list so it can be stored in Parquet.\n",
    "    df['embedding'] = [emb.tolist() for emb in all_embeddings]\n",
    "    \n",
    "    print(f\"Returning vectorized dataset with embeddings.... \")\n",
    "    return df \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    outputdf = vectorize_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb3782-dfbd-4445-aec4-9d42c6100b37",
   "metadata": {},
   "source": [
    "#### Save Vectorized Data DF as Parquet File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cadb30f-46ec-4a39-b7d9-19ba9d6b613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf.to_parquet(\"master_agent_data_with_embeddings.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
